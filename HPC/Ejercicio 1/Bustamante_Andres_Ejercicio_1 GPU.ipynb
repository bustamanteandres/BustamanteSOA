{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Prueba 1 - Vectores - GPU.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw-Vno_15t-E"
      },
      "source": [
        "# 1 Introducción\n",
        "El siguiente cuaderno realiza una conversion de un texto, aumentando el valor ASCII de cada caracter en forma paralela utilizando threads de un procesador GPU.\n",
        "\n",
        "Su objetivo es codificar un texto para que no pueda ser interpretado facilmente, para luego ser enviado y ser decodificado con su funcion inversa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cRnhv_7N4Pa"
      },
      "source": [
        "---\n",
        "# 2 Armado del ambiente\n",
        "Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74FNbCszDmw"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzQaWRTtc1Zj"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n",
        "Ejecuta el Código CPU - GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7mZSnu0M3m"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "texto_cpu =  \"Un texto es una composici\\xF3n de signos codificados en un sistema de escritura que forma una unidad de sentido.Tambi\\xE9n es una composici\\xF3n de caracteres imprimibles (con grafema) generados por un algoritmo de cifrado que, aunque no tienen sentido para cualquier persona, s\\xED puede ser descifrado por su destinatario original. En otras palabras, un texto es un entramado de signos con una intenci\\xF3n comunicativa que adquiere sentido en determinado contexto.Las ideas que comunica un texto est\\xE1n contenidas en lo que se suele denominar \\xABmacroproposiciones\\xBB, unidades estructurales de nivel superior o global, que otorgan coherencia al texto constituyendo su hilo central, el esqueleto estructural que cohesiona elementos ling\\xFC\\xEDsticos formales de alto nivel, como los t\\xEDtulos y subt\\xEDtulos, la secuencia de p\\xE1rrafos, etc. En contraste, las \\xABmicroproposiciones\\xBB son los elementos coadyuvantes de la cohesi\\xF3n de un texto, pero a nivel m\\xE1s particular o local. Esta distinci\\xF3n fue realizada por Teun van Dijk en 1980.1\\u200BEl nivel microestructural o local est\\xE1 asociado con el concepto de cohesi\\xF3n. Se refiere a uno de los fen\\xF3menos propios de la coherencia, el de las relaciones particulares y locales que se dan entre elementos ling\\xFC\\xEDsticos, tanto los que remiten unos a otros como los que tienen la funci\\xF3n de conectar y organizar.Tambi\\xE9n es un conjunto de oraciones agrupadas en p\\xE1rrafos que habla de un tema determinado.De acuerdo a Greimas, es un enunciado ya sea gr\\xE1fico o f\\xF3nico que nos permite visualizar las palabras que escuchamos y que es utilizado para manifestar el proceso ling\\xFC\\xEDstico. Mientras Hjelmslev usa ese t\\xE9rmino para designar el todo de una cadena ling\\xFC\\xEDstica ilimitada (\\xA71).En ling\\xFC\\xEDstica, no todo conjunto de signos constituye un texto.Se le llama texto a la configuraci\\xF3n de lengua o habla y se utilizan signos espec\\xEDficos (signo de la lengua o habla) y est\\xE1 organizada seg\\xFAn reglas del habla o idioma.Todo texto necesariamente posee las siguientes propiedades:Cohesi\\xF3n. Un texto cohesionado es aquel cuyas partes se encuentran unidas l\\xF3gicamente entre s\\xED, o sea, que de la lectura de una parte se puede ir a la siguiente de manera ordenada, racional. La falta de cohesi\\xF3n hace que los textos salten de una cosa a otra, sin ton ni son.Coherencia. Los textos deben ser coherentes, lo cual significa centrarse en un tema o t\\xF3pico sobre el cual van a referirse, sea el que sea. Un texto deber\\xEDa avanzar de a poco hacia la composici\\xF3n de una idea global, general, a trav\\xE9s de la exposici\\xF3n de ideas m\\xE1s peque\\xF1as o sencillas. Pero al final de la lectura de un texto coherente, uno puede explicar \\u201Cde qu\\xE9 trata\\u201D.Significado. Todo texto posee un significado a recuperar por el lector, incluso en los m\\xE1s banales o ineficientes. Pero la escritura nunca carece de significado, pues no tendr\\xEDa nada que comunicar y la lectura ser\\xEDa imposible.Progresividad. Un texto ofrece su contenido de manera progresiva, es decir, poco a poco, una oraci\\xF3n a la vez. Por eso para saber todo lo que dice debemos leerlo todo, pues a medida que avanzamos en la lectura vamos descifrando m\\xE1s y m\\xE1s del contenido de su mensaje, y si nos conformamos con la primera parte, no lo sabremos todo.Intencionalidad. Todo texto es escrito con alguna intenci\\xF3n comunicativa, o sea, con alg\\xFAn prop\\xF3sito en mente, ya sea servir de recordatorio, decirle a otra persona que haga algo, o simplemente entretener. Sea como sea, dicha intenci\\xF3n configurar\\xE1 el texto y har\\xE1 que el emisor emplee unos u otros recursos en su composici\\xF3n.Adecuaci\\xF3n. Todo texto debe adaptarse a una serie de c\\xF3digos y preceptos que sean comunes con su receptor, de manera que \\xE9ste pueda entenderlo y descifrar su contenido. Esto pasa por el modo de uso del lenguaje, tambi\\xE9n por las convenciones del g\\xE9nero, etc.\" #@param {type: \"string\"}\n",
        "# --------------------------------------------\n",
        "try:\n",
        "  from datetime import datetime\n",
        "  import pycuda.driver as cuda\n",
        "  import pycuda.autoinit\n",
        "  from pycuda.compiler import SourceModule\n",
        "  import numpy\n",
        "  # --------------------------------------------\n",
        "  # Definición de función que transforma el tiempo en  milisegundos \n",
        "  tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "  # --------------------------------------------\n",
        "  tiempo_inicio_total = datetime.now()\n",
        "  result = numpy.empty_like(texto_cpu)\n",
        "  text_size = len(texto_cpu)\n",
        "  texto_cpu_array = numpy.array(texto_cpu, dtype=str)\n",
        "  # CPU - reservo la memoria GPU.\n",
        "  texto_gpu = cuda.mem_alloc(texto_cpu_array.size * texto_cpu_array.dtype.itemsize)\n",
        "  # GPU - Copio la memoria al GPU.\n",
        "  cuda.memcpy_htod(texto_gpu, texto_cpu_array)\n",
        "  # CPU - Defino la función kernel que ejecutará en GPU.\n",
        "  module = SourceModule(\"\"\"\n",
        "  __global__ void kernel_codificar( char texto[], int size )\n",
        "  {\n",
        "    int idx = (threadIdx.x + blockIdx.x * blockDim.x) * 4;\n",
        "    if(idx < size){\n",
        "      texto[idx] ++;\n",
        "    } \n",
        "  }\n",
        "  \"\"\")\n",
        "  # CPU - Genero la función kernel.\n",
        "  kernel = module.get_function(\"kernel_codificar\")\n",
        "  tiempo_inicio_gpu = datetime.now()\n",
        "  # Armar las dimensiones correctamente.\n",
        "  dim_hilo = 256\n",
        "  dim_bloque = numpy.int( (text_size + dim_hilo-1) / dim_hilo )\n",
        "  # GPU - Ejecuta el kernel.\n",
        "  kernel(texto_gpu, numpy.int32(text_size * 4), block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "  tiempo_fin_gpu = datetime.now()\n",
        "\n",
        "  # GPU - Copio el resultado desde la memoria GPU.\n",
        "  cuda.memcpy_dtoh(result, texto_gpu)\n",
        "  tiempo_fin_total = datetime.now()\n",
        "\n",
        "  print(\"Resultado: \", result)\n",
        "  print(\"Cantidad de elementos: \", text_size )\n",
        "  print(\"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "  print(\"Tiempo Total: \", tiempo_en_ms(tiempo_fin_total - tiempo_inicio_total), \"ms\")\n",
        "  print(\"Tiempo GPU: \", tiempo_en_ms(tiempo_fin_gpu - tiempo_inicio_gpu), \"ms\")\n",
        "except Exception as excep:\n",
        "  print(\"Error: \", excep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EALIlyyG6iqP"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos de ejecución del programa\n",
        "\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  tiempo_en_ms          | Define una funcion para obtener el tiempo en milisegundos a partir de una fecha.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  len(texto_cpu) | Obtiene el tamaño del texto a convertir.\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "CPU      |  SourceModule()        | Define el código del kernel \n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria texto_GPU a CPU memoria result.\n",
        "CPU      |  print()               | Informo los resultados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzgZkrQD-UTy"
      },
      "source": [
        "---\n",
        "# 5 Conclusiones\n",
        "\n",
        "Como conclusion podemos observar que al realizar la conversion en paralelo de cada caracter de un texto, usando threads del GPU, dicha conversion se realiza mucho mas rapido que si se hiciera secuencialmente. Tambien debe destacarse que la inicializacion toma bastante tiempo, por lo cual es conveniente utilizar este tipo de procesamiento cuando el texto a convertir es bastante largo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hn6HOCYEjyY"
      },
      "source": [
        "---\n",
        "# 6 Bibliografia\n",
        "\n",
        "[1] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[3] Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n",
        "\n",
        "[4] Repositorio de PyCUDA: [WEB](https://pypi.python.org/pypi/pycuda)"
      ]
    }
  ]
}